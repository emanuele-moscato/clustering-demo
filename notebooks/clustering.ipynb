{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensional reduction and clustering of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly.graph_objs as go\n",
    "import requests\n",
    "from configparser import ConfigParser\n",
    "\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data ingestion\n",
    "\n",
    "The data is served thorugh an API running on SherlockML: we send a GET request to it in order to retrieve the dataset.\n",
    "\n",
    "The request must be authorized: the credentials are in a configuration file that is read by a parser, and are then included in the header of the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confpars = ConfigParser()\n",
    "\n",
    "confpars.read('../.credentials/credentials.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = '/get_data'\n",
    "\n",
    "headers = {\n",
    "        confpars['data_api']['header_key']: confpars['data_api']['api_key']\n",
    "    }\n",
    "\n",
    "response = requests.get(\n",
    "    url = confpars['data_api']['url']+endpoint,\n",
    "    headers = headers\n",
    ")\n",
    "\n",
    "print('Response status: '+str(response.status_code))\n",
    "\n",
    "data_df = pd.DataFrame(response.json())\n",
    "data_df = data_df.reset_index()\n",
    "data_df = data_df.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "\n",
    "Plot the data and have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = go.Scatter3d(\n",
    "    x = data_df['x'],\n",
    "    y = data_df['y'],\n",
    "    z = data_df['z'],\n",
    "    mode = 'markers',\n",
    "    marker = dict(\n",
    "        size = 2.5\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "layout = go.Layout(\n",
    "    scene = dict(\n",
    "        xaxis = dict(\n",
    "            title = 'x'\n",
    "        ),\n",
    "        yaxis = dict(\n",
    "            title = 'y'\n",
    "        ),\n",
    "        zaxis = dict(\n",
    "            title = 'z'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensional reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import principal component analysis (PCA) from SKlearn and instantiate a PCA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_dimred = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recast the data as a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit PCA to data and perform dimensional reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_dimred.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_red = pca_dimred.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the dimensionally reduced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = go.Scatter(\n",
    "    x = X_red[:,0],\n",
    "    y = X_red[:,1],\n",
    "    mode = 'markers',\n",
    "    marker = dict(\n",
    "        size = 2.5\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "layout = go.Layout(\n",
    "    xaxis = dict(\n",
    "        title = 'x (reduced)'\n",
    "    ),\n",
    "    yaxis = dict(\n",
    "        title = 'y (reduced)'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many cases in which clustering happens along one dimension much more than along another, it is useful to rescale the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_red = scaler.fit_transform(X_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = go.Scatter(\n",
    "    x = X_red[:,0],\n",
    "    y = X_red[:,1],\n",
    "    mode = 'markers',\n",
    "    marker = dict(\n",
    "        size = 2.5\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "layout = go.Layout(\n",
    "    xaxis = dict(\n",
    "        title = 'x (reduced)'\n",
    "    ),\n",
    "    yaxis = dict(\n",
    "        title = 'y (reduced)'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import KMeans from SKlearn and instantiate a KMeans model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_clustering = KMeans(n_clusters=2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit KMeans to the data and predict clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kmeans_clustering.fit(X_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_pred = kmeans_clustering.predict(X_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the dimensionally reduced data and the predicted cluster labels in a pandas dataframe and plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_df = pd.DataFrame({\n",
    "    'x_red': X_red[:,0],\n",
    "    'y_red': X_red[:,1],\n",
    "    'cluster': clusters_pred\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for label in clusters_df['cluster'].unique():\n",
    "    data.append(\n",
    "        go.Scatter(\n",
    "            x = clusters_df[clusters_df['cluster']==label]['x_red'],\n",
    "            y = clusters_df[clusters_df['cluster']==label]['y_red'],\n",
    "            mode = 'markers',\n",
    "            marker = dict(\n",
    "                size = 2.5\n",
    "            ),\n",
    "            name = 'cluster '+str(label)\n",
    "        )   \n",
    "    )\n",
    "\n",
    "layout = go.Layout(\n",
    "    xaxis = dict(\n",
    "        title = 'x (reduced)'\n",
    "    ),\n",
    "    yaxis = dict(\n",
    "        title = 'y (reduced)'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3]",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
